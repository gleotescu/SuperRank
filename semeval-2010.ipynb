{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T10:17:13.689490Z",
     "start_time": "2018-06-01T10:14:59.335175Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261\n",
      "244\n",
      "244\n",
      "Counter({14: 41, 15: 37, 16: 32, 13: 26, 18: 26, 17: 18, 20: 16, 19: 13, 21: 9, 12: 8, 10: 4, 11: 3, 22: 2, 25: 2, 23: 2, 24: 1, 28: 1, 31: 1, 36: 1, 38: 1})\n",
      "0/244\n",
      "1/244\n",
      "2/244\n",
      "3/244\n",
      "4/244\n",
      "5/244\n",
      "6/244\n",
      "7/244\n",
      "8/244\n",
      "9/244\n",
      "10/244\n",
      "11/244\n",
      "12/244\n",
      "13/244\n",
      "14/244\n",
      "15/244\n",
      "16/244\n",
      "17/244\n",
      "18/244\n",
      "19/244\n",
      "20/244\n",
      "21/244\n",
      "22/244\n",
      "23/244\n",
      "24/244\n",
      "25/244\n",
      "26/244\n",
      "27/244\n",
      "28/244\n",
      "29/244\n",
      "30/244\n",
      "31/244\n",
      "32/244\n",
      "33/244\n",
      "34/244\n",
      "35/244\n",
      "36/244\n",
      "37/244\n",
      "38/244\n",
      "39/244\n",
      "40/244\n",
      "41/244\n",
      "42/244\n",
      "43/244\n",
      "44/244\n",
      "45/244\n",
      "46/244\n",
      "47/244\n",
      "48/244\n",
      "49/244\n",
      "50/244\n",
      "51/244\n",
      "52/244\n",
      "53/244\n",
      "54/244\n",
      "55/244\n",
      "56/244\n",
      "57/244\n",
      "58/244\n",
      "59/244\n",
      "60/244\n",
      "61/244\n",
      "62/244\n",
      "63/244\n",
      "64/244\n",
      "65/244\n",
      "66/244\n",
      "67/244\n",
      "68/244\n",
      "69/244\n",
      "70/244\n",
      "71/244\n",
      "72/244\n",
      "73/244\n",
      "74/244\n",
      "75/244\n",
      "76/244\n",
      "77/244\n",
      "78/244\n",
      "79/244\n",
      "80/244\n",
      "81/244\n",
      "82/244\n",
      "83/244\n",
      "84/244\n",
      "85/244\n",
      "86/244\n",
      "87/244\n",
      "88/244\n",
      "89/244\n",
      "90/244\n",
      "91/244\n",
      "92/244\n",
      "93/244\n",
      "94/244\n",
      "95/244\n",
      "96/244\n",
      "97/244\n",
      "98/244\n",
      "99/244\n",
      "100/244\n",
      "101/244\n",
      "102/244\n",
      "103/244\n",
      "104/244\n",
      "105/244\n",
      "106/244\n",
      "107/244\n",
      "108/244\n",
      "109/244\n",
      "110/244\n",
      "111/244\n",
      "112/244\n",
      "113/244\n",
      "114/244\n",
      "115/244\n",
      "116/244\n",
      "117/244\n",
      "118/244\n",
      "119/244\n",
      "120/244\n",
      "121/244\n",
      "122/244\n",
      "123/244\n",
      "124/244\n",
      "125/244\n",
      "126/244\n",
      "127/244\n",
      "128/244\n",
      "129/244\n",
      "130/244\n",
      "131/244\n",
      "132/244\n",
      "133/244\n",
      "134/244\n",
      "135/244\n",
      "136/244\n",
      "137/244\n",
      "138/244\n",
      "139/244\n",
      "140/244\n",
      "141/244\n",
      "142/244\n",
      "143/244\n",
      "144/244\n",
      "145/244\n",
      "146/244\n",
      "147/244\n",
      "148/244\n",
      "149/244\n",
      "150/244\n",
      "151/244\n",
      "152/244\n",
      "153/244\n",
      "154/244\n",
      "155/244\n",
      "156/244\n",
      "157/244\n",
      "158/244\n",
      "159/244\n",
      "160/244\n",
      "161/244\n",
      "162/244\n",
      "163/244\n",
      "164/244\n",
      "165/244\n",
      "166/244\n",
      "167/244\n",
      "168/244\n",
      "169/244\n",
      "170/244\n",
      "171/244\n",
      "172/244\n",
      "173/244\n",
      "174/244\n",
      "175/244\n",
      "176/244\n",
      "177/244\n",
      "178/244\n",
      "179/244\n",
      "180/244\n",
      "181/244\n",
      "182/244\n",
      "183/244\n",
      "184/244\n",
      "185/244\n",
      "186/244\n",
      "187/244\n",
      "188/244\n",
      "189/244\n",
      "190/244\n",
      "191/244\n",
      "192/244\n",
      "193/244\n",
      "194/244\n",
      "195/244\n",
      "196/244\n",
      "197/244\n",
      "198/244\n",
      "199/244\n",
      "200/244\n",
      "201/244\n",
      "202/244\n",
      "203/244\n",
      "204/244\n",
      "205/244\n",
      "206/244\n",
      "207/244\n",
      "208/244\n",
      "209/244\n",
      "210/244\n",
      "211/244\n",
      "212/244\n",
      "213/244\n",
      "214/244\n",
      "215/244\n",
      "216/244\n",
      "217/244\n",
      "218/244\n",
      "219/244\n",
      "220/244\n",
      "221/244\n",
      "222/244\n",
      "223/244\n",
      "224/244\n",
      "225/244\n",
      "226/244\n",
      "227/244\n",
      "228/244\n",
      "229/244\n",
      "230/244\n",
      "231/244\n",
      "232/244\n",
      "233/244\n",
      "234/244\n",
      "235/244\n",
      "236/244\n",
      "237/244\n",
      "238/244\n",
      "239/244\n",
      "240/244\n",
      "241/244\n",
      "242/244\n",
      "243/244\n",
      "244\n",
      "244\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import os \n",
    "from os import path\n",
    "import re\n",
    "import stemming.porter2 as porter\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "\n",
    "stem = porter.stem\n",
    "tokenizer = StanfordCoreNLP(\"http://localhost\")\n",
    "\n",
    "leafs = ['test', 'train', 'trial']\n",
    "root = '../datasets/keyphrase_datasets/SemEval2010'\n",
    "stories = {}\n",
    "\n",
    "for leaf in leafs:\n",
    "    dirname = path.join(root, leaf)\n",
    "    for file in os.listdir(dirname):\n",
    "#         if not file.endswith('.txt.final'):\n",
    "#             continue\n",
    "        filename = path.join(dirname, file) \n",
    "        with open(filename, 'r') as f:\n",
    "            filecontent = f.read()\n",
    "        \n",
    "        suid = file[:-len('.txt.final')]\n",
    "        stories[suid] = {'headline' : '', 'body' : filecontent, 'suid' : suid, 'label' : leaf, 'entities' : []}\n",
    "        \n",
    "    labels = ['author', 'reader']\n",
    "    for label in labels:\n",
    "        stemmed = False\n",
    "        labelfile = path.join(root, leaf, leaf + '.' + label + '.final')\n",
    "        if not os.path.isfile(labelfile):\n",
    "            stemmed = True\n",
    "            labelfile = path.join(root, leaf, leaf + '.' + label + '.stem.final')\n",
    "            \n",
    "        with open(labelfile) as f:\n",
    "            keyphrases = {}\n",
    "            for line in f:\n",
    "                idx = line.find(':')\n",
    "                suid = line[0:idx].strip()\n",
    "                rest = line[idx+1:].strip()\n",
    "\n",
    "                entities = [{'id' : id.strip(), 'source' : label, 'stemmed' : stemmed} for id in rest.split(',') if len(id.strip()) > 0]\n",
    "                stories[suid]['entities'].extend(entities)\n",
    "                \n",
    "stories = list(stories.values())\n",
    "print(len(stories))\n",
    "stories = [s for s in stories if len(s['entities']) > 0]\n",
    "print(len(stories))\n",
    "print(len([s for s in stories if len(s['entities']) > 0]))\n",
    "\n",
    "from collections import Counter\n",
    "print(Counter([len(s['entities']) for s in stories]))\n",
    "\n",
    "def pre_process(sentence):\n",
    "    sentence = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+)|(http?://[^\\s]+))',' ',sentence) #replace urls by <url>\n",
    "    sentence = re.sub('(\\@ [^\\s]+)',' ',sentence) #replace @user268 by <user>\n",
    "    return sentence\n",
    "\n",
    "def getOffsets(surface, content):\n",
    "    return [m.span() for m in re.finditer(re.escape(surface), content)]\n",
    "\n",
    "def getSurfaceForms(form, content):\n",
    "    offsets = [getOffsets(form, content)]\n",
    "    surfaceForms = [{'form': form, 'bodyOffsets' : offsets}]\n",
    "    return surfaceForms, form   \n",
    "    \n",
    "def addSurfaceForms(story, sidx):\n",
    "    entities = [entity for entity in story['entities']]\n",
    "    headline = story['headline']\n",
    "    headline = pre_process(headline)\n",
    "    body = story['body']\n",
    "    body = pre_process(body)\n",
    "    story['headline'] = headline\n",
    "    story['body'] = body\n",
    "    story_stemmed = ' '.join([stem(word).lower() for word in \n",
    "                         tokenizer.word_tokenize(headline + '\\n' + body)])\n",
    "    story['stemmed_content'] = story_stemmed\n",
    "    \n",
    "    for entity in entities:\n",
    "        form = entity['id'].strip()\n",
    "        form = ' '.join([stem(word).lower() for word in \n",
    "                         tokenizer.word_tokenize(form)])\n",
    "        entity['stemmed'] = form\n",
    "        entity['forms'], entity['name'] = getSurfaceForms(form, story_stemmed)\n",
    "    story['entities'] = entities\n",
    "    print('%d/%d' % (sidx, len(stories)))\n",
    "[addSurfaceForms(story, sidx) for sidx, story in enumerate(stories)]\n",
    "print(len(stories))\n",
    "print(len([s for s in stories if len(s['entities']) > 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T21:07:51.568544Z",
     "start_time": "2018-05-31T21:07:51.317486Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../datasets/semeval-2010-standard.json', 'w') as f:\n",
    "    f.write(json.dumps(stories))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
